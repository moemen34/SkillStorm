{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Types of investments\n",
    "####    Long Term\n",
    "####    Short Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one Exchange-Traded Fund (ETF) representing a broad market index, \n",
    "#   QQQ\n",
    "#   SPY\n",
    "# one index mutual fund for diversified exposure to the overall market\n",
    "\n",
    "# one Forex pair to hedge against currency risk.\n",
    "\n",
    "# Split them into Long Term and Short Term 25%\n",
    "# QQQ\n",
    "# SPY\n",
    "# AGI GOLD\n",
    "# MARA Energy\n",
    "# REGN Pharma\n",
    "\n",
    "# DOGE\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "# Portfolio (Net value, cash balance, Realized profit, Unrealized profit)\n",
    "# Investement (ID, Type, #ofShares, Avg Cost, mrkt value)\n",
    "# Buy/Sell (investement_ID, #ofShares, Date)\n",
    "# candle_sticks(investement_ID, date, closePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2023-01-01'\n",
    "end_date = '2024-07-03'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "Portfolio                                                                X\n",
    "\n",
    "Total Return                                                             X\n",
    "\n",
    "Cumulative Return                                                        X\n",
    "\n",
    "Annualized Return                                                        X\n",
    "\n",
    "Volatility \n",
    "\n",
    "Sharpe Ratio \n",
    "\n",
    "Stocks and ETFs                                                          X\n",
    "\n",
    "10-Day and 100-Day Moving Averages Relative to Market Indexes            X\n",
    "\n",
    "Beta \n",
    "\n",
    "Indices                                                                  X\n",
    "\n",
    "Price Index                          \n",
    "\n",
    "Comparison to the Total Stock Market Index \n",
    "\n",
    "Forex \n",
    "\n",
    "Percentage Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Stock data through Polygon.ai and clean it using Pandas df\n",
    "\n",
    "* Convert date from unix timestamp to datetime object\n",
    "* Rename Columns     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def polygon(stock_ticker, date_start, date_end):\n",
    "\n",
    "    # Set up the GET request\n",
    "    polygon_url = 'https://api.polygon.io/v2/aggs/ticker'\n",
    "    stocksTicker = f'/{stock_ticker}'\n",
    "    timespan = '/range/1/day'\n",
    "    date_from = f'/{date_start}'\n",
    "    date_to = f'/{date_end}'\n",
    "    params = '?adjusted=true&sort=asc&'\n",
    "    polygon_key = os.environ['polygon_api_key']\n",
    "\n",
    "    params = {'adjusted':'true', \n",
    "            'sort': 'asc',\n",
    "            'apiKey': polygon_key\n",
    "            }\n",
    "\n",
    "    full_url = polygon_url + stocksTicker + timespan + date_from + date_to\n",
    "\n",
    "    # Request the data\n",
    "    response2 = requests.get(full_url, params)\n",
    "    polygon_data = response2.json()\n",
    "\n",
    "    # Access the \"results\" part of the response\n",
    "    results = polygon_data[\"results\"]\n",
    "    \n",
    "    df_polygon = pd.DataFrame(results)\n",
    "    df_polygon.head(5)\n",
    "\n",
    "    # Convert the Unix timestamp to datetime\n",
    "    df_polygon['date'] = pd.to_datetime(df_polygon['t'], unit='ms')\n",
    "\n",
    "    # Format the datetime to the desired string format (YYYY-MM-DD)\n",
    "    df_polygon['date'] = df_polygon['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Drop the unix time column\n",
    "    df_polygon = df_polygon.drop(columns=['t'])\n",
    "\n",
    "    # Rename cols\n",
    "    df_polygon.rename(columns={'v': 'volume', 'o':'open', 'c':'close', 'h':'high', 'l':'low'}, inplace=True)\n",
    "\n",
    "    #df_polygon = df_polygon[['date', 'open', 'high', 'low', 'close', 'volume', 'vw', 'n']]\n",
    "    df_polygon = df_polygon[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    \n",
    "    # Convert date from object to datetime\n",
    "    df_polygon[['date']] = df_polygon[['date']].apply(pd.to_datetime)\n",
    "    \n",
    "    #df_polygon['volume'] = df_polygon['volume'].astype(int)\n",
    "    \n",
    "    return df_polygon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Stock data through AlphaVantage(second source to validate the data) and clean it using Pandas df\n",
    "\n",
    "* Filter the entries to only include dates from 01/01/2023 to 07/03/2024\n",
    "* sort by date in asc order\n",
    "* Convert values from object to numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_vantage(stock_ticker, date_start, date_end):\n",
    "\n",
    "    # Set up GET request\n",
    "    base_url = 'https://www.alphavantage.co'\n",
    "    stocks_endpoint = '/query'\n",
    "\n",
    "    stocks_url = base_url+stocks_endpoint\n",
    "\n",
    "    api_key = os.environ['alphavantage_api_key']\n",
    "\n",
    "    params = {'function':'TIME_SERIES_DAILY', \n",
    "            'symbol': stock_ticker,\n",
    "            'outputsize': 'full',\n",
    "            'apikey' : api_key}\n",
    "\n",
    "    # Request the data        \n",
    "    alpha_response = requests.get(stocks_url, params)\n",
    "    alpha_data = alpha_response.json()\n",
    "    time_series = alpha_data[\"Time Series (Daily)\"]\n",
    "\n",
    "    # Filter the entries to only include dates from 01/01/2023 to 07/03/2024\n",
    "    start_date = datetime.strptime(date_start, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(date_end, \"%Y-%m-%d\")\n",
    "    filtered_data = {date: values for date, values in time_series.items() if (datetime.strptime(date, \"%Y-%m-%d\") >= start_date and datetime.strptime(date, \"%Y-%m-%d\") <= end_date)}\n",
    "    \n",
    "    # Switch cols and rows\n",
    "    df_alpha = pd.DataFrame.from_dict(filtered_data, orient=\"index\")\n",
    "    df_alpha.index = pd.to_datetime(df_alpha.index)\n",
    "    # Rename columns to remove the numeric prefix\n",
    "    df_alpha = df_alpha.rename(columns=lambda x: x.split(\". \")[1])  \n",
    "\n",
    "    # Reset the index to create a new numerical index\n",
    "    df_alpha = df_alpha.reset_index()\n",
    "    df_alpha.rename(columns={'index': 'date'}, inplace=True)\n",
    "\n",
    "    # Sort DataFrame by 'date' column in ascending order\n",
    "    df_alpha = df_alpha.sort_values(by='date', ascending=True)\n",
    "    df_alpha = df_alpha.reset_index()\n",
    "\n",
    "    df_alpha = df_alpha.drop(columns=['index'])\n",
    "    \n",
    "    # Convert values from object to numerics\n",
    "    df_alpha[['open', 'high', 'low', 'close', 'volume']] = df_alpha[['open', 'high', 'low', 'close', 'volume']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    return df_alpha\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "- Summary statistics\n",
    "- Comparing to other source (Alpha Vantage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Null and NaN Values through through summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "def null_check(df):\n",
    "    null_counts = df.isnull().sum()\n",
    "    return(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n",
      "________________________\n",
      "date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_1 = polygon('QQQ', start_date, end_date)\n",
    "df_2 = alpha_vantage('QQQ', start_date, end_date)\n",
    "\n",
    "print(null_check(df_1))\n",
    "print('________________________')\n",
    "print(null_check(df_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Compare the dataframes obtained\n",
    "* If the data matches, load it to our SQL database\n",
    "* If some of the data doesn't match, replace it with the average of both dfs, then store in SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames are different.\n"
     ]
    }
   ],
   "source": [
    "# Check if DataFrames from polygon and alphavantage are equal\n",
    "if df_1.equals(df_2):\n",
    "    print(\"DataFrames are identical.\")\n",
    "else:\n",
    "    print(\"DataFrames are different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>268.65</td>\n",
       "      <td>270.155</td>\n",
       "      <td>262.13</td>\n",
       "      <td>264.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>266.64</td>\n",
       "      <td>267.450</td>\n",
       "      <td>262.53</td>\n",
       "      <td>265.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>264.04</td>\n",
       "      <td>264.210</td>\n",
       "      <td>261.26</td>\n",
       "      <td>261.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>263.35</td>\n",
       "      <td>269.940</td>\n",
       "      <td>260.34</td>\n",
       "      <td>268.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>270.83</td>\n",
       "      <td>275.290</td>\n",
       "      <td>269.92</td>\n",
       "      <td>270.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    open     high     low   close\n",
       "0 2023-01-03  268.65  270.155  262.13  264.48\n",
       "1 2023-01-04  266.64  267.450  262.53  265.74\n",
       "2 2023-01-05  264.04  264.210  261.26  261.58\n",
       "3 2023-01-06  263.35  269.940  260.34  268.80\n",
       "4 2023-01-09  270.83  275.290  269.92  270.54"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()\n",
    "df_QQQ_av_no_vol = df_1[['date','open', 'high', 'low', 'close']]\n",
    "df_QQQ_av_no_vol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>268.65</td>\n",
       "      <td>270.155</td>\n",
       "      <td>262.13</td>\n",
       "      <td>264.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>266.64</td>\n",
       "      <td>267.450</td>\n",
       "      <td>262.53</td>\n",
       "      <td>265.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>264.04</td>\n",
       "      <td>264.210</td>\n",
       "      <td>261.26</td>\n",
       "      <td>261.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>263.35</td>\n",
       "      <td>269.940</td>\n",
       "      <td>260.34</td>\n",
       "      <td>268.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>270.83</td>\n",
       "      <td>275.290</td>\n",
       "      <td>269.92</td>\n",
       "      <td>270.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    open     high     low   close\n",
       "0 2023-01-03  268.65  270.155  262.13  264.48\n",
       "1 2023-01-04  266.64  267.450  262.53  265.74\n",
       "2 2023-01-05  264.04  264.210  261.26  261.58\n",
       "3 2023-01-06  263.35  269.940  260.34  268.80\n",
       "4 2023-01-09  270.83  275.290  269.92  270.54"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()\n",
    "df_QQQ_poly_no_vol = df_2[['date','open', 'high', 'low', 'close']]\n",
    "df_QQQ_poly_no_vol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames are identical.\n"
     ]
    }
   ],
   "source": [
    "# Check if DataFrames from polygon and alphavantage are equal\n",
    "if df_QQQ_poly_no_vol.equals(df_QQQ_av_no_vol):\n",
    "    print(\"DataFrames are identical.\")\n",
    "else:\n",
    "    print(\"DataFrames are different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences:\n",
      "Empty DataFrame\n",
      "Columns: [date, open, high, low, close]\n",
      "Index: []\n",
      "________________-----_________________\n",
      "Empty DataFrame\n",
      "Columns: [date, open, high, low, close]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Compare DataFrames and filter differences\n",
    "mask = df_QQQ_av_no_vol != df_QQQ_poly_no_vol\n",
    "diff_df = df_QQQ_av_no_vol[mask.any(axis=1)]  # Select rows where any difference exists\n",
    "diff_df2 = df_QQQ_poly_no_vol[mask.any(axis=1)]  # Select rows where any difference exists\n",
    "\n",
    "print(\"Differences:\")\n",
    "print(diff_df)\n",
    "print('_________________________________________')\n",
    "print(diff_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
